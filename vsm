import math
from collections import Counter

def build_tf_matrix(documents):
    processed = []
    vocab_set = set()

    for doc in documents:
        tokens = doc.lower().split()
        processed.append(tokens)
        vocab_set.update(tokens)

    vocab = sorted(vocab_set)
    tf_matrix = []
    for doc_tokens in processed:
        counts = Counter(doc_tokens)
        tf_row = [counts.get(term, 0) for term in vocab]
        tf_matrix.append(tf_row)

    return vocab, tf_matrix

def compute_idf(vocab, tf_matrix):
    N = len(tf_matrix)
    idf = []
    for term_idx in range(len(vocab)):
        df = sum(1 for doc in tf_matrix if doc[term_idx] > 0)  # doc frequency
        idf.append(math.log(N / df) if df > 0 else 0)
    return idf

def compute_tfidf(tf_matrix, idf):
    return [[tf * idf[i] for i, tf in enumerate(doc)] for doc in tf_matrix]

def query_to_vector(query, vocab, idf):
    query_tf = Counter(query.lower().split())
    return [query_tf.get(term, 0) * idf[i] for i, term in enumerate(vocab)]

def cosine_similarity(v1, v2):
    dot = sum(a * b for a, b in zip(v1, v2))
    mag1 = math.sqrt(sum(a * a for a in v1))
    mag2 = math.sqrt(sum(b * b for b in v2))
    return dot / (mag1 * mag2) if mag1 and mag2 else 0

def jaccard_coefficient(v1, v2):
    b1 = [1 if x > 0 else 0 for x in v1]
    b2 = [1 if x > 0 else 0 for x in v2]
    intersection = sum(a & b for a, b in zip(b1, b2))
    union = sum(a | b for a, b in zip(b1, b2))
    return intersection / union if union > 0 else 0

def dice_coefficient(v1, v2):
    b1 = [1 if x > 0 else 0 for x in v1]
    b2 = [1 if x > 0 else 0 for x in v2]
    intersection = sum(a & b for a, b in zip(b1, b2))
    total = sum(b1) + sum(b2)
    return (2 * intersection) / total if total > 0 else 0

def dot_product(v1, v2):
    return sum(a * b for a, b in zip(v1, v2))

def search(query, vocab, tfidf_matrix, idf, similarity="cosine", top_k=5):
    qvec = query_to_vector(query, vocab, idf)

    similarities = []
    for doc_id, dvec in enumerate(tfidf_matrix):
        if similarity == "cosine":
            sim = cosine_similarity(qvec, dvec)
        elif similarity == "jaccard":
            sim = jaccard_coefficient(qvec, dvec)
        elif similarity == "dice":
            sim = dice_coefficient(qvec, dvec)
        elif similarity == "dot":
            sim = dot_product(qvec, dvec)
        else:
            sim = cosine_similarity(qvec, dvec)  # default

        similarities.append((doc_id, sim))

    similarities.sort(key=lambda x: x[1], reverse=True)
    return similarities[:top_k]

if __name__ == "__main__":
    documents = [
        "information retrieval system",
        "machine learning data",
        "web search engine"
    ]

    vocab, tf_matrix = build_tf_matrix(documents)
    idf = compute_idf(vocab, tf_matrix)
    tfidf_matrix = compute_tfidf(tf_matrix, idf)

    query = "information system"

    print("Cosine:", search(query, vocab, tfidf_matrix, idf, "cosine"))
    print("Jaccard:", search(query, vocab, tfidf_matrix, idf, "jaccard"))
    print("Dice:", search(query, vocab, tfidf_matrix, idf, "dice"))
    print("Dot Product:", search(query, vocab, tfidf_matrix, idf, "dot"))
